"""
SSRF Scanner - Three Phase Implementation
Phase 1: Intelligent Discovery
Phase 2: Contextual Testing  
Phase 3: Advanced Verification
"""

import asyncio
import json
import re
from typing import Dict, List, Any
from urllib.parse import urlparse, urljoin
import random
import string

# Browser automation imports - try playwright first, then pyppeteer
BROWSER_AVAILABLE = False
BROWSER_TYPE = None

try:
    from playwright.async_api import async_playwright
    BROWSER_AVAILABLE = True
    BROWSER_TYPE = 'playwright'
except ImportError:
    try:
        from pyppeteer import launch
        from pyppeteer.errors import TimeoutError as PyppeteerTimeoutError
        BROWSER_AVAILABLE = True
        BROWSER_TYPE = 'pyppeteer'
    except ImportError:
        pass


async def phase1_intelligent_discovery(target_url: str, config: Any) -> Dict[str, Any]:
    """
    Phase 1: Intelligent Discovery ðŸ•µï¸â€â™‚ï¸
    
    Uses a headless browser to:
    - Render JavaScript-heavy pages
    - Capture network traffic (API calls)
    - Map API endpoints with methods and request structures
    """
    endpoints = []
    captured_requests = []
    
    if not BROWSER_AVAILABLE:
        print(f"[Phase 1] Browser automation not available - skipping browser discovery")
        print(f"[Phase 1] Install playwright or pyppeteer: pip install playwright")
        return {'endpoints': [], 'captured_requests': []}
    
    browser = None
    context = None
    page = None
    
    try:
        print(f"[Phase 1] Launching headless browser ({BROWSER_TYPE})...")
        
        if BROWSER_TYPE == 'playwright':
            # Use Playwright
            playwright = await async_playwright().start()
            browser = await playwright.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                ]
            )
            context = await browser.new_context(
                ignore_https_errors=True,
                bypass_csp=True
            )
            page = await context.new_page()
        else:
            # Use Pyppeteer
            browser = await launch({
                'headless': True,
                'args': [
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-web-security',
                ]
            })
            page = await browser.newPage()
        
        # Set up network request interception
        network_requests = []
        
        async def intercept_request(request):
            """Intercept and log all network requests"""
            try:
                if BROWSER_TYPE == 'playwright':
                    url = request.url
                    method = request.method
                    headers = request.headers
                    post_data = request.post_data
                else:
                    url = request.url
                    method = request.method
                    headers = request.headers
                    post_data = request.postData
                
                # Log the request
                request_info = {
                    'url': url,
                    'method': method,
                    'headers': headers,
                    'timestamp': asyncio.get_event_loop().time()
                }
                
                # Parse POST data if available
                if post_data:
                    try:
                        # Try to parse as JSON
                        request_info['body'] = json.loads(post_data)
                        request_info['content_type'] = 'application/json'
                    except:
                        # Store as raw data
                        request_info['body'] = post_data
                        request_info['content_type'] = headers.get('content-type', 'unknown')
                
                network_requests.append(request_info)
                
                # Identify API endpoints
                parsed = urlparse(url)
                if any(keyword in parsed.path.lower() for keyword in ['/api/', '/rest/', '/graphql', '/v1/', '/v2/']):
                    endpoint_info = {
                        'url': url,
                        'method': method,
                        'type': 'api',
                        'path': parsed.path,
                        'has_body': post_data is not None
                    }
                    
                    if endpoint_info not in endpoints:
                        endpoints.append(endpoint_info)
                        print(f"[Phase 1] Discovered API endpoint: {method} {parsed.path}")
                
            except Exception as e:
                print(f"[Phase 1] Error intercepting request: {e}")
        
        # Enable request interception
        if BROWSER_TYPE == 'playwright':
            page.on('request', lambda req: asyncio.ensure_future(intercept_request(req)))
        else:
            await page.setRequestInterception(True)
            page.on('request', lambda req: asyncio.ensure_future(intercept_request(req)))
        
        # Navigate to the target URL
        print(f"[Phase 1] Navigating to {target_url}...")
        try:
            if BROWSER_TYPE == 'playwright':
                await page.goto(target_url, wait_until='networkidle', timeout=30000)
            else:
                await page.goto(target_url, {'waitUntil': 'networkidle2', 'timeout': 30000})
        except Exception as e:
            print(f"[Phase 1] Navigation timeout/error - continuing with captured requests: {e}")
        
        # Wait a bit for dynamic content to load
        await asyncio.sleep(3)
        
        # Interact with the page to trigger more API calls
        print(f"[Phase 1] Interacting with page elements...")
        
        try:
            if BROWSER_TYPE == 'playwright':
                # Playwright interaction
                buttons = await page.query_selector_all('button, a.btn, input[type="submit"]')
                for i, button in enumerate(buttons[:5]):
                    try:
                        await button.click(timeout=2000)
                        await asyncio.sleep(1)
                    except:
                        pass
            else:
                # Pyppeteer interaction
                buttons = await page.querySelectorAll('button, a.btn, input[type="submit"]')
                for i, button in enumerate(buttons[:5]):
                    try:
                        await button.click()
                        await asyncio.sleep(1)
                    except:
                        pass
        except Exception as e:
            print(f"[Phase 1] Error during page interaction: {e}")
        
        # Process captured requests
        print(f"[Phase 1] Processing {len(network_requests)} captured requests...")
        
        for req in network_requests:
            # Filter for requests with bodies (POST, PUT, PATCH) OR GET with parameters
            if req['method'] in ['POST', 'PUT', 'PATCH'] and 'body' in req:
                captured_requests.append(req)
                print(f"[Phase 1] Captured {req['method']} request to {urlparse(req['url']).path}")
            elif req['method'] == 'GET':
                # Also capture GET requests to API endpoints for parameter testing
                parsed_url = urlparse(req['url'])
                if any(keyword in parsed_url.path.lower() for keyword in ['/api/', '/rest/']):
                    # Create a synthetic body with URL parameters for testing
                    req['body'] = {'url': 'http://example.com', 'uri': 'http://example.com'}
                    req['synthetic'] = True
                    captured_requests.append(req)
                    print(f"[Phase 1] Captured {req['method']} API request to {parsed_url.path}")
        
    except Exception as e:
        print(f"[Phase 1] Error during browser discovery: {e}")
    
    finally:
        if page:
            try:
                await page.close()
            except:
                pass
        if context:
            try:
                await context.close()
            except:
                pass
        if browser:
            try:
                await browser.close()
            except:
                pass
    
    return {
        'endpoints': endpoints,
        'captured_requests': captured_requests
    }


async def phase2_contextual_testing(captured_requests: List[Dict], baseline: Dict[str, Any],
                                   enable_dangerous: bool, canary_domain: str,
                                   config: Any, scanner_instance: Any) -> Dict[str, Any]:
    """
    Phase 2: Contextual Testing ðŸ”¬
    
    Uses captured API requests to:
    - Replicate valid request structures
    - Systematically mutate JSON values with SSRF payloads
    - Test real parameters the application uses
    """
    vulnerabilities = []
    parameters_tested = 0
    payloads_tested = 0
    
    print(f"[Phase 2] Testing {len(captured_requests)} captured requests...")
    
    # Get SSRF payloads from scanner instance
    payloads = scanner_instance._select_payloads(enable_dangerous, canary_domain)
    
    import httpx
    
    async with httpx.AsyncClient(verify=False, follow_redirects=False, timeout=15) as client:
        for req_idx, captured_req in enumerate(captured_requests):
            url = captured_req['url']
            method = captured_req['method']
            original_body = captured_req.get('body')
            
            if not original_body or not isinstance(original_body, dict):
                continue
            
            print(f"[Phase 2] Testing request {req_idx + 1}/{len(captured_requests)}: {method} {urlparse(url).path}")
            
            # Iterate through each key in the JSON body
            for key in original_body.keys():
                parameters_tested += 1
                original_value = original_body[key]
                
                print(f"[Phase 2]   Testing parameter: {key}")
                
                # Test each payload on this parameter
                for payload_type, payload in payloads[:5]:  # Limit payloads per parameter
                    payloads_tested += 1
                    
                    # Create mutated request body
                    mutated_body = original_body.copy()
                    mutated_body[key] = payload
                    
                    try:
                        # Send the mutated request
                        import time
                        start_time = time.time()
                        
                        if method == 'GET':
                            # For GET requests, add as query parameters
                            from urllib.parse import urlencode
                            query_string = urlencode(mutated_body)
                            test_url = f"{url}?{query_string}" if '?' not in url else f"{url}&{query_string}"
                            response = await client.get(
                                test_url,
                                headers=captured_req.get('headers', {})
                            )
                        elif method == 'POST':
                            response = await client.post(
                                url,
                                json=mutated_body,
                                headers=captured_req.get('headers', {})
                            )
                        elif method == 'PUT':
                            response = await client.put(
                                url,
                                json=mutated_body,
                                headers=captured_req.get('headers', {})
                            )
                        elif method == 'PATCH':
                            response = await client.patch(
                                url,
                                json=mutated_body,
                                headers=captured_req.get('headers', {})
                            )
                        else:
                            continue
                        
                        elapsed = (time.time() - start_time) * 1000
                        
                        # Analyze response for SSRF indicators
                        ssrf_evidence = scanner_instance._analyze_response_for_ssrf(
                            response, baseline, payload, payload_type, elapsed
                        )
                        
                        if ssrf_evidence['is_vulnerable']:
                            print(f"[Phase 2]     âœ“ Found vulnerability in parameter '{key}'!")
                            
                            # Create vulnerability
                            from backend.scanner.base_module import Vulnerability, SeverityLevel
                            
                            vuln = Vulnerability(
                                module=scanner_instance.name,
                                name=f"Contextual SSRF in JSON parameter '{key}'",
                                description=f"Parameter '{key}' in {method} request to {urlparse(url).path} is vulnerable to SSRF",
                                severity=scanner_instance._determine_severity(payload_type, ssrf_evidence),
                                confidence=ssrf_evidence['confidence'] * 1.2,  # Higher confidence for contextual testing
                                affected_urls=[url],
                                evidence={
                                    'parameter': key,
                                    'payload': payload,
                                    'payload_type': payload_type,
                                    'method': method,
                                    'original_value': str(original_value),
                                    'request_body': mutated_body,
                                    'indicators': ssrf_evidence.get('indicators', []),
                                    'response_snippet': ssrf_evidence.get('response_snippet', '')[:500],
                                    'discovery_method': 'browser_capture'
                                },
                                remediation=scanner_instance._get_remediation(payload_type),
                                references=[
                                    "https://owasp.org/www-community/attacks/Server_Side_Request_Forgery"
                                ],
                                cwe_ids=["CWE-918"]
                            )
                            vulnerabilities.append(vuln)
                            
                            # Don't test more payloads for this parameter
                            if ssrf_evidence['confidence'] >= 0.8:
                                break
                    
                    except Exception as e:
                        print(f"[Phase 2]     Error testing payload: {e}")
                        continue
    
    return {
        'vulnerabilities': vulnerabilities,
        'parameters_tested': parameters_tested,
        'payloads_tested': payloads_tested
    }


async def phase3_advanced_verification(vulnerabilities: List[Any], canary_domain: str,
                                      config: Any) -> Dict[str, Any]:
    """
    Phase 3: Advanced Verification âœ…
    
    Implements Out-of-Band (OOB) verification:
    - Uses canary domains with unique subdomains
    - Confirms SSRF by checking for DNS/HTTP callbacks
    - Provides 100% confidence for confirmed vulnerabilities
    """
    confirmed_vulnerabilities = []
    
    if not canary_domain:
        print("[Phase 3] No canary domain provided - skipping OOB verification")
        return {'confirmed_vulnerabilities': []}
    
    print(f"[Phase 3] Verifying {len(vulnerabilities)} potential vulnerabilities...")
    
    # Find vulnerabilities that used DNS OOB payloads
    dns_oob_vulns = [
        v for v in vulnerabilities 
        if v.evidence.get('payload_type') == 'dns_oob'
    ]
    
    for vuln in dns_oob_vulns:
        payload = vuln.evidence.get('payload', '')
        
        # Extract unique subdomain from payload
        try:
            parsed = urlparse(payload)
            hostname = parsed.hostname
            if hostname and '.' in hostname:
                unique_subdomain = hostname.split('.')[0]
                
                print(f"[Phase 3] Checking for OOB interaction: {unique_subdomain}.{canary_domain}")
                
                # Wait for potential DNS lookup/HTTP request
                await asyncio.sleep(5)
                
                # In a real implementation, this would query a collaborator service
                # For now, we'll simulate the check
                
                # Example integration with a collaborator service:
                # validation_result = await check_collaborator_service(canary_domain, unique_subdomain)
                
                # Placeholder validation
                validation_result = {
                    'interaction_detected': False,  # Would be True if DNS/HTTP request detected
                    'interaction_type': None,
                    'timestamp': None,
                    'details': {
                        'note': 'Integrate with Burp Collaborator, interact.sh, or custom DNS server',
                        'canary_domain': canary_domain,
                        'unique_subdomain': unique_subdomain
                    }
                }
                
                if validation_result['interaction_detected']:
                    print(f"[Phase 3]   âœ“ OOB interaction confirmed!")
                    
                    # Create confirmed vulnerability
                    from backend.scanner.base_module import Vulnerability, SeverityLevel
                    
                    confirmed_vuln = Vulnerability(
                        module=vuln.module,
                        name=f"CONFIRMED Out-of-Band SSRF in parameter '{vuln.evidence['parameter']}'",
                        description=f"Parameter '{vuln.evidence['parameter']}' confirmed to make out-of-band requests. "
                                  f"DNS lookup/HTTP request detected from target server.",
                        severity=SeverityLevel.CRITICAL,
                        confidence=1.0,  # 100% confidence for confirmed OOB
                        affected_urls=vuln.affected_urls,
                        evidence={
                            **vuln.evidence,
                            'oob_confirmed': True,
                            'oob_validation': validation_result,
                            'unique_subdomain': unique_subdomain,
                            'verification_method': 'dns_oob'
                        },
                        remediation=vuln.remediation,
                        references=vuln.references,
                        cwe_ids=vuln.cwe_ids
                    )
                    confirmed_vulnerabilities.append(confirmed_vuln)
                else:
                    print(f"[Phase 3]   âœ— No OOB interaction detected")
                    # Update original vulnerability with OOB attempt info
                    vuln.evidence['oob_attempted'] = True
                    vuln.evidence['oob_validation'] = validation_result
                    
        except Exception as e:
            print(f"[Phase 3] Error during OOB verification: {e}")
    
    return {
        'confirmed_vulnerabilities': confirmed_vulnerabilities
    }
